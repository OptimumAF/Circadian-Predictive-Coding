"""Generate README charts and animation from benchmark outputs.

This script intentionally uses Pillow instead of matplotlib to keep figure
generation stable in environments where compiled plotting dependencies may be
unavailable.
"""

from __future__ import annotations

import argparse
import csv
from dataclasses import dataclass
import json
from pathlib import Path
from typing import Callable

from PIL import Image, ImageDraw, ImageFont


@dataclass(frozen=True)
class SummaryRow:
    model_name: str
    test_accuracy_mean: float
    train_samples_per_second_mean: float
    inference_latency_p95_ms_mean: float
    balanced_score: float


@dataclass(frozen=True)
class MetricSpec:
    title: str
    subtitle: str
    objective_note: str
    y_label: str
    value_getter: Callable[[SummaryRow], float]
    value_formatter: Callable[[float], str]
    y_min: float | None = None
    y_max: float | None = None
    y_padding_ratio: float = 0.08
    clamp_zero: bool = True


MODEL_ORDER = ["BackpropResNet50", "PredictiveCodingResNet50", "CircadianPredictiveCodingResNet50"]
MODEL_LABELS = {
    "BackpropResNet50": "Backprop",
    "PredictiveCodingResNet50": "Predictive",
    "CircadianPredictiveCodingResNet50": "Circadian",
}
MODEL_COLORS = {
    "BackpropResNet50": (46, 97, 173),
    "PredictiveCodingResNet50": (61, 157, 86),
    "CircadianPredictiveCodingResNet50": (189, 102, 36),
}


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Generate README benchmark figures.")
    parser.add_argument(
        "--summary-csv",
        type=str,
        default="benchmark_multiseed_cifar100_summary.csv",
        help="Path to the summary CSV generated by run_multiseed_resnet_benchmark.py",
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="docs/figures",
        help="Directory to write figure artifacts.",
    )
    parser.add_argument(
        "--sleep-cycles",
        type=int,
        default=24,
        help="Cycle count for the illustrative circadian GIF timeline.",
    )
    parser.add_argument(
        "--start-hidden",
        type=int,
        default=384,
        help="Starting hidden dimension for the illustrative circadian GIF timeline.",
    )
    parser.add_argument(
        "--splits",
        type=int,
        default=12,
        help="Total split events represented in the illustrative circadian GIF timeline.",
    )
    parser.add_argument(
        "--prunes",
        type=int,
        default=2,
        help="Total prune events represented in the illustrative circadian GIF timeline.",
    )
    return parser.parse_args()


def load_summary_rows(path: Path) -> list[SummaryRow]:
    if not path.exists():
        raise FileNotFoundError(f"Summary CSV does not exist: {path}")

    rows_by_model: dict[str, SummaryRow] = {}
    with path.open("r", encoding="utf-8", newline="") as handle:
        reader = csv.DictReader(handle)
        for raw in reader:
            model_name = str(raw["model_name"])
            rows_by_model[model_name] = SummaryRow(
                model_name=model_name,
                test_accuracy_mean=float(raw["test_accuracy_mean"]),
                train_samples_per_second_mean=float(raw["train_samples_per_second_mean"]),
                inference_latency_p95_ms_mean=float(raw["inference_latency_p95_ms_mean"]),
                balanced_score=float(raw.get("balanced_score", "0.0")),
            )

    missing = [name for name in MODEL_ORDER if name not in rows_by_model]
    if missing:
        raise ValueError(f"Missing models in summary CSV: {missing}")
    return [rows_by_model[name] for name in MODEL_ORDER]


def draw_bar_chart(
    rows: list[SummaryRow],
    title: str,
    subtitle: str,
    value_getter: Callable[[SummaryRow], float],
    value_formatter: Callable[[float], str],
    output_path: Path,
    objective_note: str,
    y_min: float | None = None,
    y_max: float | None = None,
    y_padding_ratio: float = 0.08,
    clamp_zero: bool = True,
) -> None:
    width = 1280
    height = 720
    image = Image.new("RGB", (width, height), (248, 250, 252))
    draw = ImageDraw.Draw(image)
    font_title = ImageFont.load_default()
    font_body = ImageFont.load_default()

    draw.text((50, 28), title, fill=(20, 20, 24), font=font_title)
    draw.text((50, 52), subtitle, fill=(90, 94, 103), font=font_body)
    draw.text((50, 72), objective_note, fill=(120, 124, 132), font=font_body)

    left = 100
    top = 110
    right = width - 80
    bottom = height - 120
    chart_height = bottom - top
    chart_width = right - left
    draw.rectangle([(left, top), (right, bottom)], outline=(215, 220, 228), width=2)

    values = [float(value_getter(row)) for row in rows]
    chart_min, chart_max = resolve_y_range(
        values=values,
        requested_min=y_min,
        requested_max=y_max,
        padding_ratio=y_padding_ratio,
        clamp_zero=clamp_zero,
    )
    chart_span = max(chart_max - chart_min, 1e-8)

    tick_count = 5
    for tick_index in range(tick_count + 1):
        tick_ratio = tick_index / tick_count
        y = bottom - int(tick_ratio * chart_height)
        tick_value = chart_min + tick_ratio * chart_span
        draw.line([(left, y), (right, y)], fill=(234, 238, 244), width=1)
        draw.text((left - 72, y - 6), f"{tick_value:.2f}", fill=(107, 112, 120), font=font_body)

    for index, row in enumerate(rows):
        value = float(value_getter(row))
        x0 = left + int((index + 0.15) * chart_width / len(rows))
        x1 = left + int((index + 0.85) * chart_width / len(rows))
        ratio = (value - chart_min) / chart_span
        bar_height = max(int(chart_height * ratio), 3)
        y0 = bottom - bar_height
        y1 = bottom

        draw.rectangle([(x0, y0), (x1, y1)], fill=MODEL_COLORS[row.model_name], outline=(40, 40, 44))
        draw.text((x0, bottom + 12), MODEL_LABELS[row.model_name], fill=(20, 20, 24), font=font_body)
        draw.text((x0, y0 - 16), value_formatter(value), fill=(20, 20, 24), font=font_body)

    draw.text(
        (50, height - 42),
        "Source: benchmark_multiseed_cifar100_summary.csv",
        fill=(120, 124, 132),
        font=font_body,
    )
    output_path.parent.mkdir(parents=True, exist_ok=True)
    image.save(output_path, format="PNG")


def resolve_y_range(
    values: list[float],
    requested_min: float | None,
    requested_max: float | None,
    padding_ratio: float,
    clamp_zero: bool,
) -> tuple[float, float]:
    if requested_min is not None and requested_max is not None:
        return requested_min, requested_max
    value_min = min(values)
    value_max = max(values)
    span = value_max - value_min
    if span < 1e-12:
        base_pad = max(abs(value_max) * 0.05, 1e-3)
    else:
        base_pad = span * padding_ratio
    y_min = value_min - base_pad if requested_min is None else requested_min
    y_max = value_max + base_pad if requested_max is None else requested_max
    if clamp_zero and y_min > 0.0:
        y_min = max(0.0, y_min)
    if y_max <= y_min:
        y_max = y_min + max(abs(y_min) * 0.1, 1.0)
    return y_min, y_max


def write_plotly_bar_html(
    rows: list[SummaryRow],
    title: str,
    y_label: str,
    value_getter: Callable[[SummaryRow], float],
    output_path: Path,
    objective_note: str,
    y_min: float | None = None,
    y_max: float | None = None,
    y_padding_ratio: float = 0.08,
    clamp_zero: bool = True,
) -> None:
    labels = [MODEL_LABELS[row.model_name] for row in rows]
    values = [float(value_getter(row)) for row in rows]
    colors = [rgb_to_hex(MODEL_COLORS[row.model_name]) for row in rows]
    resolved_min, resolved_max = resolve_y_range(
        values=values,
        requested_min=y_min,
        requested_max=y_max,
        padding_ratio=y_padding_ratio,
        clamp_zero=clamp_zero,
    )
    payload = {
        "labels": labels,
        "values": values,
        "colors": colors,
        "title": title,
        "y_label": y_label,
        "objective_note": objective_note,
        "range": [resolved_min, resolved_max],
    }
    html = f"""<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>{title}</title>
  <script src="https://cdn.plot.ly/plotly-2.35.2.min.js"></script>
</head>
<body style="font-family: Arial, sans-serif; margin: 0; background: #f8fafc;">
  <div id="chart" style="width: 100%; max-width: 1080px; height: 640px; margin: 24px auto;"></div>
  <script>
    const payload = {json.dumps(payload)};
    const trace = {{
      x: payload.labels,
      y: payload.values,
      type: "bar",
      marker: {{ color: payload.colors }},
      text: payload.values.map(v => String(v)),
      textposition: "outside",
      cliponaxis: false
    }};
    const layout = {{
      title: {{ text: payload.title + "<br><sup>" + payload.objective_note + "</sup>" }},
      yaxis: {{ title: payload.y_label, range: payload.range }},
      xaxis: {{ title: "Model" }},
      margin: {{ l: 80, r: 40, t: 100, b: 80 }},
      paper_bgcolor: "#f8fafc",
      plot_bgcolor: "#ffffff"
    }};
    Plotly.newPlot("chart", [trace], layout, {{responsive: true}});
  </script>
</body>
</html>
"""
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(html, encoding="utf-8")


def rgb_to_hex(color: tuple[int, int, int]) -> str:
    return f"#{color[0]:02x}{color[1]:02x}{color[2]:02x}"


def default_metric_specs() -> list[MetricSpec]:
    return [
        MetricSpec(
            title="Accuracy",
            subtitle="Mean test accuracy",
            objective_note="Higher is better",
            y_label="Accuracy",
            value_getter=lambda row: row.test_accuracy_mean,
            value_formatter=lambda value: f"{value:.3f}",
            y_min=0.0,
            y_max=1.0,
            clamp_zero=False,
        ),
        MetricSpec(
            title="Training Throughput",
            subtitle="Mean samples / second",
            objective_note="Higher is better",
            y_label="Train SPS",
            value_getter=lambda row: row.train_samples_per_second_mean,
            value_formatter=lambda value: f"{value:.0f}",
            y_padding_ratio=0.10,
        ),
        MetricSpec(
            title="Inference Latency P95",
            subtitle="Mean latency (ms)",
            objective_note="Lower is better",
            y_label="P95 latency (ms)",
            value_getter=lambda row: row.inference_latency_p95_ms_mean,
            value_formatter=lambda value: f"{value:.2f}",
            y_padding_ratio=0.12,
        ),
        MetricSpec(
            title="Balanced Score",
            subtitle="Composite utility score",
            objective_note="Higher is better",
            y_label="Balanced score",
            value_getter=lambda row: row.balanced_score,
            value_formatter=lambda value: f"{value:.3f}",
            y_min=0.0,
            y_max=1.0,
            clamp_zero=False,
        ),
    ]


def draw_metric_panel(
    draw: ImageDraw.ImageDraw,
    rows: list[SummaryRow],
    spec: MetricSpec,
    panel_box: tuple[int, int, int, int],
    font_title: ImageFont.ImageFont | ImageFont.FreeTypeFont,
    font_body: ImageFont.ImageFont | ImageFont.FreeTypeFont,
) -> None:
    panel_left, panel_top, panel_right, panel_bottom = panel_box
    draw.rounded_rectangle(
        [(panel_left, panel_top), (panel_right, panel_bottom)],
        radius=12,
        fill=(255, 255, 255),
        outline=(216, 222, 232),
        width=2,
    )
    draw.text((panel_left + 14, panel_top + 12), spec.title, fill=(24, 24, 30), font=font_title)
    draw.text((panel_left + 14, panel_top + 30), spec.subtitle, fill=(98, 104, 114), font=font_body)
    draw.text(
        (panel_left + 14, panel_top + 48),
        spec.objective_note,
        fill=(121, 126, 136),
        font=font_body,
    )

    chart_left = panel_left + 52
    chart_right = panel_right - 20
    chart_top = panel_top + 74
    chart_bottom = panel_bottom - 44
    chart_height = chart_bottom - chart_top
    chart_width = chart_right - chart_left
    draw.rectangle([(chart_left, chart_top), (chart_right, chart_bottom)], outline=(220, 225, 234), width=1)

    values = [float(spec.value_getter(row)) for row in rows]
    chart_min, chart_max = resolve_y_range(
        values=values,
        requested_min=spec.y_min,
        requested_max=spec.y_max,
        padding_ratio=spec.y_padding_ratio,
        clamp_zero=spec.clamp_zero,
    )
    chart_span = max(chart_max - chart_min, 1e-8)

    for tick_index in range(5):
        tick_ratio = tick_index / 4
        y = chart_bottom - int(tick_ratio * chart_height)
        tick_value = chart_min + tick_ratio * chart_span
        draw.line([(chart_left, y), (chart_right, y)], fill=(236, 240, 246), width=1)
        draw.text((chart_left - 40, y - 6), f"{tick_value:.2f}", fill=(110, 115, 124), font=font_body)

    for index, row in enumerate(rows):
        value = float(spec.value_getter(row))
        x0 = chart_left + int((index + 0.12) * chart_width / len(rows))
        x1 = chart_left + int((index + 0.88) * chart_width / len(rows))
        ratio = (value - chart_min) / chart_span
        bar_height = max(int(chart_height * ratio), 3)
        y0 = chart_bottom - bar_height
        draw.rectangle([(x0, y0), (x1, chart_bottom)], fill=MODEL_COLORS[row.model_name], outline=(40, 40, 44))
        draw.text((x0, chart_bottom + 8), MODEL_LABELS[row.model_name], fill=(32, 33, 38), font=font_body)
        draw.text((x0, y0 - 14), spec.value_formatter(value), fill=(22, 22, 26), font=font_body)


def draw_compact_overview_chart(
    rows: list[SummaryRow],
    specs: list[MetricSpec],
    output_path: Path,
) -> None:
    width = 1500
    height = 920
    image = Image.new("RGB", (width, height), (246, 249, 253))
    draw = ImageDraw.Draw(image)
    font_title = ImageFont.load_default()
    font_body = ImageFont.load_default()

    draw.text((34, 20), "Benchmark Overview (Compact)", fill=(18, 20, 25), font=font_title)
    draw.text(
        (34, 40),
        "Multi-seed CIFAR-100 summary across key metrics for all three models.",
        fill=(92, 98, 108),
        font=font_body,
    )

    legend_y = 60
    legend_x = 34
    for model_name in MODEL_ORDER:
        color = MODEL_COLORS[model_name]
        label = MODEL_LABELS[model_name]
        draw.rectangle([(legend_x, legend_y), (legend_x + 16, legend_y + 12)], fill=color, outline=(60, 60, 64))
        draw.text((legend_x + 22, legend_y), label, fill=(36, 38, 44), font=font_body)
        legend_x += 160

    panel_gap = 18
    panel_width = (width - 34 * 2 - panel_gap) // 2
    panel_height = (height - 96 - 38 - panel_gap) // 2
    panel_top_start = 96

    for index, spec in enumerate(specs):
        row_index = index // 2
        col_index = index % 2
        panel_left = 34 + col_index * (panel_width + panel_gap)
        panel_top = panel_top_start + row_index * (panel_height + panel_gap)
        panel_right = panel_left + panel_width
        panel_bottom = panel_top + panel_height
        draw_metric_panel(
            draw=draw,
            rows=rows,
            spec=spec,
            panel_box=(panel_left, panel_top, panel_right, panel_bottom),
            font_title=font_title,
            font_body=font_body,
        )

    draw.text(
        (34, height - 24),
        "Source: benchmark_multiseed_cifar100_summary.csv",
        fill=(118, 122, 131),
        font=font_body,
    )
    output_path.parent.mkdir(parents=True, exist_ok=True)
    image.save(output_path, format="PNG")


def write_plotly_overview_html(
    rows: list[SummaryRow],
    specs: list[MetricSpec],
    output_path: Path,
) -> None:
    labels = [MODEL_LABELS[row.model_name] for row in rows]
    colors = [rgb_to_hex(MODEL_COLORS[row.model_name]) for row in rows]

    metrics: list[dict[str, object]] = []
    for spec in specs:
        values = [float(spec.value_getter(row)) for row in rows]
        resolved_min, resolved_max = resolve_y_range(
            values=values,
            requested_min=spec.y_min,
            requested_max=spec.y_max,
            padding_ratio=spec.y_padding_ratio,
            clamp_zero=spec.clamp_zero,
        )
        metrics.append(
            {
                "title": spec.title,
                "subtitle": spec.subtitle,
                "objective_note": spec.objective_note,
                "y_label": spec.y_label,
                "values": values,
                "formatted_values": [spec.value_formatter(value) for value in values],
                "range": [resolved_min, resolved_max],
            }
        )

    payload = {"labels": labels, "colors": colors, "metrics": metrics}
    html = f"""<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Benchmark Overview</title>
  <script src="https://cdn.plot.ly/plotly-2.35.2.min.js"></script>
</head>
<body style="font-family: Arial, sans-serif; margin: 0; background: #f7f9fc;">
  <div id="chart" style="width: 100%; max-width: 1200px; height: 900px; margin: 18px auto;"></div>
  <script>
    const payload = {json.dumps(payload)};
    const traces = [];
    const annotations = [];
    payload.metrics.forEach((metric, idx) => {{
      const axisIndex = idx + 1;
      const xRef = axisIndex === 1 ? "x" : "x" + axisIndex;
      const yRef = axisIndex === 1 ? "y" : "y" + axisIndex;
      traces.push({{
        type: "bar",
        x: payload.labels,
        y: metric.values,
        marker: {{ color: payload.colors }},
        text: metric.formatted_values,
        textposition: "outside",
        cliponaxis: false,
        xaxis: xRef,
        yaxis: yRef,
        showlegend: false
      }});

      const col = idx % 2;
      const row = Math.floor(idx / 2);
      const xCenter = col === 0 ? 0.225 : 0.775;
      const yTop = row === 0 ? 1.12 : 0.56;
      annotations.push({{
        xref: "paper",
        yref: "paper",
        x: xCenter,
        y: yTop,
        text: "<b>" + metric.title + "</b><br><span style='color:#5e6672'>" + metric.objective_note + "</span>",
        showarrow: false,
        align: "center",
        font: {{size: 12, color: "#1e2430"}}
      }});
    }});

    const layout = {{
      title: {{
        text: "Benchmark Overview (Compact)<br><sup>Multi-seed CIFAR-100 summary</sup>"
      }},
      grid: {{ rows: 2, columns: 2, pattern: "independent" }},
      paper_bgcolor: "#f7f9fc",
      plot_bgcolor: "#ffffff",
      margin: {{ l: 70, r: 35, t: 120, b: 70 }},
      annotations: annotations
    }};

    payload.metrics.forEach((metric, idx) => {{
      const axisIndex = idx + 1;
      const xAxisName = axisIndex === 1 ? "xaxis" : "xaxis" + axisIndex;
      const yAxisName = axisIndex === 1 ? "yaxis" : "yaxis" + axisIndex;
      layout[xAxisName] = {{ title: "Model" }};
      layout[yAxisName] = {{ title: metric.y_label, range: metric.range }};
    }});

    Plotly.newPlot("chart", traces, layout, {{responsive: true}});
  </script>
</body>
</html>
"""
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(html, encoding="utf-8")


def build_delta_sequence(cycles: int, splits: int, prunes: int) -> list[int]:
    if cycles <= 0:
        raise ValueError("cycles must be positive.")
    deltas = [0 for _ in range(cycles)]

    if splits > 0:
        split_positions = evenly_spaced_positions(cycles=cycles, count=splits, from_start=True)
        for index in split_positions:
            deltas[index] += 1
    if prunes > 0:
        prune_positions = evenly_spaced_positions(cycles=cycles, count=prunes, from_start=False)
        for index in prune_positions:
            deltas[index] -= 1
    return deltas


def evenly_spaced_positions(cycles: int, count: int, from_start: bool) -> list[int]:
    if count <= 0:
        return []
    positions: list[int] = []
    for i in range(count):
        ratio = (i + 1) / (count + 1)
        base = int(round(ratio * (cycles - 1)))
        positions.append(base)
    positions = sorted(set(positions))
    while len(positions) < count:
        next_pos = len(positions) % cycles
        if next_pos not in positions:
            positions.append(next_pos)
    positions = sorted(positions[:count])
    if from_start:
        return positions
    return [cycles - 1 - position for position in positions]


def make_hidden_series(start_hidden: int, deltas: list[int]) -> list[int]:
    values = [start_hidden]
    current = start_hidden
    for delta in deltas:
        current += delta
        values.append(current)
    return values


def draw_circadian_gif(
    output_path: Path,
    start_hidden: int,
    sleep_cycles: int,
    splits: int,
    prunes: int,
) -> None:
    deltas = build_delta_sequence(cycles=sleep_cycles, splits=splits, prunes=prunes)
    hidden_values = make_hidden_series(start_hidden=start_hidden, deltas=deltas)
    min_hidden = min(hidden_values)
    max_hidden = max(hidden_values)
    value_span = max(max_hidden - min_hidden, 1)

    width = 960
    height = 540
    left = 80
    right = width - 60
    top = 90
    bottom = height - 90
    chart_width = right - left
    chart_height = bottom - top

    frames: list[Image.Image] = []
    for frame_index in range(len(hidden_values)):
        image = Image.new("RGB", (width, height), (250, 251, 253))
        draw = ImageDraw.Draw(image)
        font = ImageFont.load_default()
        draw.text((36, 24), "Circadian Sleep Dynamics (Illustrative)", fill=(20, 20, 24), font=font)
        draw.text(
            (36, 44),
            "Wake updates chemicals; sleep cycles trigger split/prune adaptation.",
            fill=(92, 96, 104),
            font=font,
        )

        draw.rectangle([(left, top), (right, bottom)], outline=(212, 217, 224), width=2)
        for tick in range(5):
            y = top + int(tick * chart_height / 4)
            draw.line([(left, y), (right, y)], fill=(236, 239, 244), width=1)

        points: list[tuple[int, int]] = []
        for idx in range(frame_index + 1):
            x = left + int(idx * chart_width / max(len(hidden_values) - 1, 1))
            normalized = (hidden_values[idx] - min_hidden) / value_span
            y = bottom - int(normalized * chart_height)
            points.append((x, y))
        if len(points) > 1:
            draw.line(points, fill=(189, 102, 36), width=4)
        if points:
            px, py = points[-1]
            draw.ellipse([(px - 5, py - 5), (px + 5, py + 5)], fill=(189, 102, 36), outline=(70, 40, 18))

        current_cycle = frame_index
        hidden_now = hidden_values[frame_index]
        draw.text(
            (36, height - 58),
            f"Cycle {current_cycle:02d}/{sleep_cycles:02d} | hidden_dim={hidden_now} | splits={splits} | prunes={prunes}",
            fill=(22, 22, 26),
            font=font,
        )
        draw.text((36, height - 38), "Illustrative animation (not a direct training trace).", fill=(112, 116, 124), font=font)
        frames.append(image)

    output_path.parent.mkdir(parents=True, exist_ok=True)
    first, *rest = frames
    first.save(
        output_path,
        format="GIF",
        save_all=True,
        append_images=rest,
        duration=260,
        loop=0,
    )


def main() -> None:
    args = parse_args()
    summary_path = Path(args.summary_csv)
    output_dir = Path(args.output_dir)
    rows = load_summary_rows(summary_path)
    specs = default_metric_specs()
    specs_by_title = {spec.title: spec for spec in specs}

    draw_compact_overview_chart(
        rows=rows,
        specs=specs,
        output_path=output_dir / "benchmark_overview_compact.png",
    )
    write_plotly_overview_html(
        rows=rows,
        specs=specs,
        output_path=output_dir / "interactive_benchmark_overview.html",
    )

    draw_bar_chart(
        rows=rows,
        title="Accuracy Comparison (Higher Is Better)",
        subtitle="Mean test accuracy across multi-seed CIFAR-100 benchmark",
        value_getter=specs_by_title["Accuracy"].value_getter,
        value_formatter=specs_by_title["Accuracy"].value_formatter,
        output_path=output_dir / "benchmark_accuracy.png",
        objective_note=specs_by_title["Accuracy"].objective_note,
        y_min=specs_by_title["Accuracy"].y_min,
        y_max=specs_by_title["Accuracy"].y_max,
        clamp_zero=specs_by_title["Accuracy"].clamp_zero,
    )
    draw_bar_chart(
        rows=rows,
        title="Training Throughput (Higher Is Better)",
        subtitle="Mean training samples per second",
        value_getter=specs_by_title["Training Throughput"].value_getter,
        value_formatter=specs_by_title["Training Throughput"].value_formatter,
        output_path=output_dir / "benchmark_train_speed.png",
        objective_note=specs_by_title["Training Throughput"].objective_note,
        y_padding_ratio=specs_by_title["Training Throughput"].y_padding_ratio,
    )
    draw_bar_chart(
        rows=rows,
        title="Inference Latency P95 (Lower Is Better)",
        subtitle="Mean p95 inference latency in milliseconds",
        value_getter=specs_by_title["Inference Latency P95"].value_getter,
        value_formatter=lambda value: f"{value:.2f} ms",
        output_path=output_dir / "benchmark_inference_latency_p95.png",
        objective_note=specs_by_title["Inference Latency P95"].objective_note,
        y_padding_ratio=specs_by_title["Inference Latency P95"].y_padding_ratio,
    )

    write_plotly_bar_html(
        rows=rows,
        title="Accuracy Comparison",
        y_label="Mean test accuracy",
        value_getter=specs_by_title["Accuracy"].value_getter,
        output_path=output_dir / "interactive_benchmark_accuracy.html",
        objective_note=specs_by_title["Accuracy"].objective_note,
        y_min=specs_by_title["Accuracy"].y_min,
        y_max=specs_by_title["Accuracy"].y_max,
        clamp_zero=specs_by_title["Accuracy"].clamp_zero,
    )
    write_plotly_bar_html(
        rows=rows,
        title="Training Throughput",
        y_label="Mean training samples per second",
        value_getter=specs_by_title["Training Throughput"].value_getter,
        output_path=output_dir / "interactive_benchmark_train_speed.html",
        objective_note=specs_by_title["Training Throughput"].objective_note,
        y_padding_ratio=specs_by_title["Training Throughput"].y_padding_ratio,
    )
    write_plotly_bar_html(
        rows=rows,
        title="Inference Latency P95",
        y_label="Mean p95 inference latency (ms)",
        value_getter=specs_by_title["Inference Latency P95"].value_getter,
        output_path=output_dir / "interactive_benchmark_inference_latency_p95.html",
        objective_note=specs_by_title["Inference Latency P95"].objective_note,
        y_padding_ratio=specs_by_title["Inference Latency P95"].y_padding_ratio,
    )
    draw_circadian_gif(
        output_path=output_dir / "circadian_sleep_dynamics.gif",
        start_hidden=args.start_hidden,
        sleep_cycles=args.sleep_cycles,
        splits=args.splits,
        prunes=args.prunes,
    )
    print(f"Wrote figures to {output_dir}")


if __name__ == "__main__":
    main()
